{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from scipy.sparse import *\n",
    "\n",
    "from spektral.layers import GCNConv\n",
    "\n",
    "from keras.layers import Input,Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import Model\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_reader(path):\n",
    "    \"\"\"\n",
    "    Function to read the graph from the path.\n",
    "    :param path: Path to the edge list.\n",
    "    :return graph: NetworkX object returned.\n",
    "    \"\"\"\n",
    "    graph = nx.from_edgelist(pd.read_csv(path).values.tolist())\n",
    "    return graph\n",
    "\n",
    "def feature_reader(path):\n",
    "    \"\"\"\n",
    "    Reading the sparse feature matrix stored as csv from the disk.\n",
    "    :param path: Path to the csv file.\n",
    "    :return features: Dense matrix of features.\n",
    "    \"\"\"\n",
    "    features = pd.read_csv(path)\n",
    "    node_index = features[\"node_id\"].values.tolist()\n",
    "    feature_index = features[\"feature_id\"].values.tolist()\n",
    "    feature_values = features[\"value\"].values.tolist()\n",
    "    node_count = max(node_index)+1\n",
    "    feature_count = max(feature_index)+1\n",
    "    features = coo_matrix((feature_values, (node_index, feature_index)), shape=(node_count, feature_count)).toarray()\n",
    "    return features\n",
    "\n",
    "def target_reader(path):\n",
    "    \"\"\"\n",
    "    Reading the target vector from disk.\n",
    "    :param path: Path to the target.\n",
    "    :return target: Target vector.\n",
    "    \"\"\"\n",
    "    target = np.array(pd.read_csv(path)[\"target\"]).reshape(-1,1)\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = graph_reader('data/edges.csv')\n",
    "X = feature_reader('data/features.csv')\n",
    "y = target_reader('data/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/995qt8yn7pb1m4_qv3tw0g040000gr/T/ipykernel_22448/2819385825.py:2: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph info:  Graph with 14746 nodes and 236222 edges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jb/995qt8yn7pb1m4_qv3tw0g040000gr/T/ipykernel_22448/2819385825.py:3: DeprecationWarning: info is deprecated and will be removed in version 3.0.\n",
      "\n",
      "  print('Graph info: ', nx.info(G))\n"
     ]
    }
   ],
   "source": [
    "#obtain the adjacency matrix (A)\n",
    "A = nx.adjacency_matrix(G)\n",
    "print('Graph info: ', nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (14746, 4)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X,dtype=int)\n",
    "N = X.shape[0] #the number of nodes\n",
    "F = X.shape[1] #the size of node features\n",
    "print('X shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 4)            0           ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " input_14 (InputLayer)          [(None, 14746)]      0           []                               \n",
      "                                                                                                  \n",
      " gcn_conv_7 (GCNConv)           (None, 16)           64          ['dropout_12[0][0]',             \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 16)           0           ['gcn_conv_7[0][0]']             \n",
      "                                                                                                  \n",
      " gcn_conv_8 (GCNConv)           (None, 20)           320         ['dropout_13[0][0]',             \n",
      "                                                                  'input_14[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 384\n",
      "Trainable params: 384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "channels = 16           # Number of channels in the first layer\n",
    "dropout = 0.5           # Dropout rate for the features\n",
    "l2_reg = 5e-4           # L2 regularization rate\n",
    "learning_rate = 1e-2    # Learning rate\n",
    "epochs = 200            # Number of training epochs\n",
    "es_patience = 10        # Patience for early stopping\n",
    "num_classes =  20       # Number of classes\n",
    "\n",
    "# Preprocessing operations\n",
    "A = GCNConv.preprocess(A).astype('f4')\n",
    "\n",
    "# Model definition\n",
    "X_in = Input(shape=(F, ))\n",
    "fltr_in = Input((N, ), sparse=True)\n",
    "\n",
    "dropout_1 = Dropout(dropout)(X_in)\n",
    "graph_conv_1 = GCNConv(channels,\n",
    "                         activation='relu',\n",
    "                         kernel_regularizer=regularizers.l2(l2_reg),\n",
    "                         use_bias=False)([dropout_1, fltr_in])\n",
    "\n",
    "dropout_2 = Dropout(dropout)(graph_conv_1)\n",
    "graph_conv_2 = GCNConv(num_classes,\n",
    "                         activation='softmax',\n",
    "                         use_bias=False)([dropout_2, fltr_in])\n",
    "\n",
    "# Build model\n",
    "model = Model(inputs=[X_in, fltr_in], outputs=graph_conv_2)\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              weighted_metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14746, 14746)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14746, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9879, 14746)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data in train and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "A_train, A_test, _, _ = train_test_split(A, y, test_size=0.33, random_state=42)\n",
    "\n",
    "A_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 20) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/j.cloarec/Desktop/test_spektal_wine.ipynb Cell 10'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=1'>2</a>\u001b[0m validation_data \u001b[39m=\u001b[39m ([X_test,A_test], y_test)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit([X_train,A_train],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=4'>5</a>\u001b[0m           y_train,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=5'>6</a>\u001b[0m           epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=6'>7</a>\u001b[0m           batch_size\u001b[39m=\u001b[39;49mN,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=7'>8</a>\u001b[0m           validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=8'>9</a>\u001b[0m           shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/j.cloarec/Desktop/test_spektal_wine.ipynb#ch0000007?line=9'>10</a>\u001b[0m           callbacks\u001b[39m=\u001b[39;49mEarlyStopping(patience\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,  restore_best_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n",
      "File \u001b[0;32m/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/jb/995qt8yn7pb1m4_qv3tw0g040000gr/T/__autograph_generated_filed7dsxc7m.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/losses.py\", line 1787, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/opt/miniconda3/envs/ML/lib/python3.9/site-packages/keras/backend.py\", line 5119, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 20) are incompatible\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train model\n",
    "validation_data = ([X_test,A_test], y_test)\n",
    "\n",
    "model.fit([X_train,A_train],\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          batch_size=N,\n",
    "          validation_data=validation_data,\n",
    "          shuffle=False,\n",
    "          callbacks=EarlyStopping(patience=10,  restore_best_weights=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d55d083706a9c020f114bf1c514291b6a16f7df9c2c6a6da9b89d58e3afcb641"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
